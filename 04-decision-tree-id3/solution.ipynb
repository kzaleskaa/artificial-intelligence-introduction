{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Zadanie 4 - Drzewo decyzyjne ID3**\n",
    "\n",
    "Cel zadania polega na implementacji drzewa decyzyjnego tworzonego algorytmem ID3 z ograniczeniem maksymalnej głębokości drzewa, jak również na stworzeniu i zbadaniu jakości klasyfikatora dla zbioru danych [Tic-Tac-Toe Endgame](https://archive.ics.uci.edu/dataset/101/tic+tac+toe+endgame).\n",
    "\n",
    "**Kroki do wykonania:**\n",
    "- Zaimplementuj drzewo decyzyjne ID3 (z ograniczeniem jego maksymalnej głębokości).\n",
    "- Zbadaj skuteczność działania kasyfikatora dla zbioru danych Tic-Tac-Toe Endgame, obliczając dokładność i macierz pomyłek.\n",
    "\n",
    "**Uwagi**\n",
    "- Należy pamiętać o podziale danych na zbiory trenujący, walidacyjny i testowy.\n",
    "- Zaimplementowana metoda powinna być uniwersalna - nie należy \"zaszywać\" na sztywno w kodzie np. nazwy pliku ze zbiorem danych czy wartości atrybutów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset\n",
    "tic_tac_toe_endgame = fetch_ucirepo(id=101)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = tic_tac_toe_endgame.data.features\n",
    "y = tic_tac_toe_endgame.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable information\n",
    "print(tic_tac_toe_endgame.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode target\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_VARIABLES_VALUES = ['x', 'o', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.feature_name = None    # feature used for splitting\n",
    "        self.value = None           # value of the feature used for splitting\n",
    "        self.label = None           # label of the node (only for leaf nodes)\n",
    "        self.children = []          # list of child nodes each representing a split\n",
    "\n",
    "    def add_child(self, child: 'Node') -> None:\n",
    "        self.children.append(child)\n",
    "\n",
    "    def set_feature_name(self, feature_name: str) -> None:\n",
    "        self.feature_name = feature_name\n",
    "\n",
    "    def set_value(self, value: str) -> None:\n",
    "        self.value = value\n",
    "\n",
    "    def set_label(self, label: str) -> None:\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeID3:\n",
    "    def __init__(self, max_depth: int = 5, leaf_classes: List[str] = ALL_VARIABLES_VALUES) -> None:\n",
    "        self.max_depth = max_depth\n",
    "        self.leaf_classes = leaf_classes\n",
    "        self.root = None\n",
    "\n",
    "    def _calculate_entropy(self, y: pd.Series) -> float:\n",
    "        probabilities = np.bincount(y) / len(y)\n",
    "        return - np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
    "\n",
    "    def _calculate_information_gain(self, X: pd.DataFrame, y: pd.Series, feature: str) -> float:\n",
    "        total_data_entropy = self._calculate_entropy(y)\n",
    "        unique_values, unique_value_counts = np.unique(X[feature], return_counts=True)\n",
    "        subset_entropy = 0\n",
    "        for value, value_count in zip(unique_values, unique_value_counts):\n",
    "            subset_y = y[X[feature] == value]\n",
    "            subset_entropy += value_count / len(X) * self._calculate_entropy(subset_y)\n",
    "\n",
    "        return total_data_entropy - subset_entropy\n",
    "\n",
    "    def _choose_best_feature(self, X: pd.DataFrame, y: pd.Series) -> str:\n",
    "        gains = {\n",
    "            feature: self._calculate_information_gain(X, y, feature)\n",
    "            for feature in X.columns\n",
    "        }\n",
    "        best_feature = max(gains, key=gains.get)\n",
    "        return best_feature, gains[best_feature]\n",
    "\n",
    "    def fit(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:\n",
    "        self.root = Node()\n",
    "        self._id3(self.root, X_train, y_train, 0)\n",
    "\n",
    "    def _id3(self, node: Node, X: pd.DataFrame, y: pd.Series, depth: int) -> None:\n",
    "        if depth >= self.max_depth or len(np.unique(y)) == 1:\n",
    "            # set the value of the node to the most common class in the dataset\n",
    "            node.set_label(y.mode()[0])\n",
    "            return None\n",
    "\n",
    "        split_feature, information_gain = self._choose_best_feature(X, y)\n",
    "\n",
    "        if information_gain <= 0:\n",
    "            node.set_label(y.mode()[0])\n",
    "            return None\n",
    "\n",
    "        node.set_feature_name(split_feature)\n",
    "\n",
    "        if self.leaf_classes is None:\n",
    "            self.leaf_classes = np.unique(y)\n",
    "\n",
    "        for value in self.leaf_classes:\n",
    "            child_node = Node()\n",
    "            child_node.set_value(value)\n",
    "            node.add_child(child_node)\n",
    "\n",
    "            subset = X[X[split_feature] == value]\n",
    "\n",
    "            if subset.empty:\n",
    "                child_node.set_label(y.mode()[0])\n",
    "            else:\n",
    "                self._id3(child_node, X[X[split_feature] == value], y[X[split_feature] == value], depth + 1)\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> List[str]:\n",
    "        y_pred = []\n",
    "        for i in range(len(X)):\n",
    "            y_pred.append(self.predict_single(self.root, X.iloc[i]))\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def predict_single(self, node: Node, x: pd.Series) -> str:\n",
    "        if node.label is not None:\n",
    "            return node.label\n",
    "\n",
    "        for child in node.children:\n",
    "            if x[node.feature_name] == child.value:\n",
    "                return self.predict_single(child, x)\n",
    "\n",
    "    def print_tree(self, node: Node, level: int = 0, prefix: str = \"\") -> None:\n",
    "        indent = \"   \" * level\n",
    "        if node.value is not None:\n",
    "            prefix = f\"{prefix} ({node.value})\"\n",
    "\n",
    "        if node.feature_name is None:\n",
    "            print(f\"{indent}{prefix}: Leaf: {node.label}\")\n",
    "        else:\n",
    "            print(f\"{indent}{prefix}: {node.feature_name}\")\n",
    "\n",
    "        for child in node.children:\n",
    "            self.print_tree(child, level + 1, prefix=f\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_test_split(X, y, train_val_test_split = [0.8, 0.1, 0.1]):\n",
    "    # train is now train_val_test_split[0] of the entire data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1 - train_val_test_split[0], random_state = 42)\n",
    "    # split the test set into validation and test sets\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = train_val_test_split[2]/\n",
    "                                                    (train_val_test_split[1] + train_val_test_split[2]), random_state = 42)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = get_train_val_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3_tree = DecisionTreeID3(max_depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3_tree.print_tree(id3_tree.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.inverse_transform([1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check different depths of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPTH_RANGE = range(1, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_different_depths(depth_range: List[int] = DEPTH_RANGE) -> Tuple[List[float], List[np.ndarray]]:\n",
    "    accuracy, cm = [], []\n",
    "\n",
    "    for depth in depth_range:\n",
    "        id3_tree = DecisionTreeID3(max_depth = depth)\n",
    "        id3_tree.fit(X_train, y_train)\n",
    "        y_pred = id3_tree.predict(X_val)\n",
    "        accuracy.append(accuracy_score(y_val, y_pred))\n",
    "        cm.append(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "    return accuracy, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, cm = check_different_depths(DEPTH_RANGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cm(cm: np.ndarray, title: str) -> None:\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predykcja\")\n",
    "    plt.ylabel(\"Prawdziwa wartość\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(depth_range: List[int], accuracy: List[float]) -> None:\n",
    "    plt.plot(depth_range, accuracy)\n",
    "    plt.title(\"Dokładność w zależności od głębokości drzewa\")\n",
    "    plt.xlabel(\"Głębokość drzewa\")\n",
    "    plt.ylabel(\"Dokładność\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(depth_range: List[int], cm: List[np.ndarray]) -> None:\n",
    "    for i in range(len(cm)):\n",
    "        plt.figure()\n",
    "        visualize_cm(cm[i], f\"Macierz pomyłek dla głębokości drzewa {depth_range[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(DEPTH_RANGE, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(DEPTH_RANGE, cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyniki dla najlepszej głębokości drzewa na zbiorze testowym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3_tree = DecisionTreeID3(max_depth = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = id3_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = accuracy_score(y_test, test_pred)\n",
    "test_cm = confusion_matrix(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_cm(test_cm, \"Macierz pomyłek dla zbioru testowego, głębokość drzewa 6\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
